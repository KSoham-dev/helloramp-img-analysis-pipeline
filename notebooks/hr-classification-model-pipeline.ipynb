{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! uv add joblib scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from torchvision import transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EfficientNet.from_pretrained('efficientnet-b5').to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((380, 380)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': '2aef963a-6866a00bc97fc6a75b49511b_slot_images_dicky_door_open_view.jpg',\n",
       " 'shoot_category': 'interior'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = list(Path('car-img-hr').glob('*.jpg'))\n",
    "batch_size = 32\n",
    "all_features = []\n",
    "with open('project-6-at-2025-11-18-10-24-3493761b.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "result = [{'image': t['file_upload'], 'shoot_category': next((r['value']['choices'][0] for r in t['annotations'][0]['result'] if r.get('from_name') == 'shoot_category'), None)} for t in data if t['annotations']]\n",
    "\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No match for 6866a00bc97fc6a75b49511b_slot_images_engine_left_side_hinge___apron_view.jpg, assigned random label: 1\n",
      "Batch labels: [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "Warning: No match for 6866a00bc97fc6a75b49511b_slot_images_engine_bonnet_open_front_view.jpg, assigned random label: 1\n",
      "Batch labels: [0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0]\n",
      "\n",
      "Total images: 57\n",
      "Features shape: (57, 2048)\n",
      "Labels shape: (57,)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "result_dict = {}\n",
    "for res in result:\n",
    "    label_studio_filename = os.path.basename(res[\"image\"])\n",
    "    actual_filename = re.sub(r'^[a-f0-9]+-', '', label_studio_filename)\n",
    "    result_dict[actual_filename] = res[\"shoot_category\"]\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(0, len(image_paths), batch_size):\n",
    "    batch_paths = image_paths[i:i+batch_size]\n",
    "    batch = torch.stack([transform(Image.open(p).convert('RGB')) for p in batch_paths]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model.extract_features(batch)\n",
    "        features = torch.nn.functional.adaptive_avg_pool2d(features, 1).squeeze(-1).squeeze(-1)\n",
    "    \n",
    "    \n",
    "    all_features.append(features.cpu().numpy())\n",
    "    \n",
    "    current_labels = []\n",
    "    for path in batch_paths:\n",
    "        filename = os.path.basename(path)\n",
    "        \n",
    "        if filename in result_dict:\n",
    "            category = result_dict[filename]\n",
    "            label = 0 if category.lower() == 'exterior' else 1\n",
    "            current_labels.append(label)\n",
    "        else:\n",
    "            random_label = random.choice([0, 1])\n",
    "            current_labels.append(random_label)\n",
    "            print(f\"Warning: No match for {filename}, assigned random label: {random_label}\")\n",
    "    \n",
    "    all_labels.extend(current_labels)\n",
    "    print(f\"Batch labels: {current_labels}\")\n",
    "\n",
    "\n",
    "features_array = np.vstack(all_features)\n",
    "labels_array = np.array(all_labels)\n",
    "\n",
    "print(f\"\\nTotal images: {len(image_paths)}\")\n",
    "print(f\"Features shape: {features_array.shape}\")\n",
    "print(f\"Labels shape: {labels_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 2048)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 2048) (45,)\n",
      "(12, 2048) (12,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_array,\n",
    "    labels_array,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels_array \n",
    ")\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_torch = torch.tensor(y_train, dtype=torch.long) \n",
    "X_test_torch = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_torch = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNNHead(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\n",
    "# embeddings_2d = tsne.fit_transform(features_array)\n",
    "\n",
    "# # Create visualization\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# colors = ['blue', 'red']\n",
    "# labels = ['Exterior', 'Interior']\n",
    "\n",
    "# for i in range(2):\n",
    "#     mask = labels_array == i\n",
    "#     plt.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "#                 c=colors[i], label=labels[i], alpha=0.6, s=100)\n",
    "\n",
    "# plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "# plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "# plt.title('t-SNE Visualization of EfficientNet-B5 Embeddings', fontsize=14)\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('tsne_embeddings.png', dpi=300)\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8759220,
     "sourceId": 13763895,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
